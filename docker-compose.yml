name: devops-project-sk

services:
  reverse-proxy:
    image: ${REGISTRY:-ghcr.io/sarkel/devops-project-sk}/web:${TAG:-latest}
    build:
      context: .
      dockerfile: docker/Dockerfile.proxy
      target: final
    container_name: dp-reverse-proxy
    restart: unless-stopped
    env_file: .env
    ports:
      - "${PROXY_PORT}:80"
    volumes:
      - nginx_logs:/var/log/nginx
    networks:
      - front_net
    depends_on:
      api:
        condition: service_healthy
      grafana:
        condition: service_healthy
    healthcheck:
      test: [ "CMD-SHELL", "wget -qO- http://localhost/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s

  scheduler:
    image: ${REGISTRY:-ghcr.io/sarkel/devops-project-sk}/scheduler:${TAG:-latest}
    build:
      context: .
      dockerfile: docker/Dockerfile.scheduler
    container_name: dp-scheduler
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      - crawler
    networks:
      - back_net

  migration_runner:
    image: ${REGISTRY:-ghcr.io/sarkel/devops-project-sk}/migrations:${TAG:-latest}
    build:
      context: .
      dockerfile: docker/Dockerfile.migrations
      target: runner
    container_name: dp-migration-runner
    env_file: .env
    restart: no
    environment:
      DB_PORT: 5432
      DB_HOST: db
    depends_on:
      db:
        condition: service_healthy
    networks:
      - back_net

  seeder:
    image: ${REGISTRY:-ghcr.io/sarkel/devops-project-sk}/seeder:${TAG:-latest}
    build:
      context: .
      dockerfile: docker/Dockerfile.app
      target: seeder
    container_name: dp-seeder-runner
    env_file: .env
    restart: no
    environment:
      DB_PORT: 5432
      DB_HOST: db
    depends_on:
      db:
        condition: service_healthy
      migration_runner:
        condition: service_completed_successfully
    networks:
      - back_net
    volumes:
      - seeder:/seeder

  db:
    image: postgres:18-alpine
    container_name: dp-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: $DB_USER
      POSTGRES_PASSWORD: $DB_PASSWORD
      POSTGRES_DB: $DB_NAME
    expose:
      - 5432
    volumes:
      - db_data:/var/lib/postgresql/data
    networks:
      - back_net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $DB_USER -d $DB_NAME"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  mqtt:
    image: ${REGISTRY:-ghcr.io/sarkel/devops-project-sk}/mqtt:${TAG:-latest}
    build:
      context: .
      dockerfile: docker/Dockerfile.mqtt
    container_name: dp-mqtt
    restart: unless-stopped
    env_file:
      - .env
    expose:
      - 1883
    volumes:
      - ./docker/mosquitto/data:/mosquitto/data
      - ./docker/mosquitto/log:/mosquitto/log
    networks:
      - back_net
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 1883 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s

  api:
    image: ${REGISTRY:-ghcr.io/sarkel/devops-project-sk}/api:${TAG:-latest}
    build:
      context: .
      dockerfile: docker/Dockerfile.app
      target: api
    restart: unless-stopped
    container_name: dp-api
    environment:
      DB_HOST: db
      DB_PORT: 5432
      API_PORT: 8080
    env_file: .env
    networks:
      - front_net
      - back_net
    expose:
      - 8080
    depends_on:
      db:
        condition: service_healthy
      migration_runner:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "wget --header=\"${AUTH_KEY_NAME}: ${AUTH_KEY_VAL}\" -qO- http://localhost:8080/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s

  reader:
    image: ${REGISTRY:-ghcr.io/sarkel/devops-project-sk}/reader:${TAG:-latest}
    build:
      context: .
      dockerfile: docker/Dockerfile.app
      target: reader
    restart: unless-stopped
    container_name: dp-reader
    environment:
      DB_HOST: db
      DB_PORT: 5432
      MQTT_BROKER_HOST: mqtt
      MQTT_BROKER_PORT: 1883
    env_file: .env
    depends_on:
      db:
        condition: service_healthy
      mqtt:
        condition: service_healthy
      migration_runner:
        condition: service_completed_successfully
    networks:
      - back_net

  crawler:
    image: ${REGISTRY:-ghcr.io/sarkel/devops-project-sk}/crawler:${TAG:-latest}
    build:
      context: .
      dockerfile: docker/Dockerfile.app
      target: crawler
    container_name: dp-crawler
    entrypoint: ["/bin/sh", "-c", "sleep infinity"]
    restart: no
    environment:
      MQTT_BROKER_HOST: mqtt
      MQTT_BROKER_PORT: 1883
      DB_HOST: db
      DB_PORT: 5432
    env_file: .env
    depends_on:
      mqtt:
        condition: service_healthy
      db:
        condition: service_healthy
      reader:
        condition: service_started
      migration_runner:
        condition: service_completed_successfully
    networks:
      - back_net
      - back_bridge_net # egress only


  # metrics & observability
  prometheus:
    image: ${REGISTRY:-ghcr.io/sarkel/devops-project-sk}/prometheus:${TAG:-latest}
    build:
      context: .
      dockerfile: docker/Dockerfile.prometheus
    container_name: dp-prometheus
    restart: unless-stopped
    expose:
      - 9090
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    networks:
      - back_net
    healthcheck:
      test: [ "CMD-SHELL", "wget -q --spider http://localhost:9090/-/healthy || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  loki:
    image: ${REGISTRY:-ghcr.io/sarkel/devops-project-sk}/loki:${TAG:-latest}
    build:
      context: .
      dockerfile: docker/Dockerfile.loki
    container_name: dp-loki
    restart: unless-stopped
    command: -config.file=/etc/loki/local-config.yaml
    expose:
      - 3100
    networks:
      - back_net
    healthcheck:
      test: [ "CMD-SHELL", "wget -q --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s

  promtail:
    image: ${REGISTRY:-ghcr.io/sarkel/devops-project-sk}/promtail:${TAG:-latest}
    build:
      context: .
      dockerfile: docker/Dockerfile.promtail
    container_name: dp-promtail
    restart: unless-stopped
    volumes:
      - nginx_logs:/var/log/nginx:ro
      - seed_output:/var/log/seed_output:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    networks:
      - back_net
    healthcheck:
      test: [ "CMD-SHELL", "wget -q --spider http://localhost:9080/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s

  grafana:
    image: ${REGISTRY:-ghcr.io/sarkel/devops-project-sk}/grafana:${TAG:-latest}
    build:
      context: .
      dockerfile: docker/Dockerfile.grafana
    container_name: dp-grafana
    restart: unless-stopped
    env_file:
      - .env
    expose:
      - 3000
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}
      - GF_AUTH_ANONYMOUS_ENABLED=false
#      -- Reverse proxy configuration
      - GF_SERVER_DOMAIN=localhost
      - GF_SERVER_ROOT_URL=%(protocol)s://%(domain)s:%(http_port)s/monitoring/
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
      - loki
    networks:
      - back_net
      - front_net
    healthcheck:
      # We must include '/monitoring' in the URL because of GF_SERVER_ROOT_URL
      test: [ "CMD-SHELL", "curl -f http://localhost:3000/monitoring/api/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s


volumes:
  db_data:
    driver: local
  nginx_logs:
    driver: local
  seed_output:
    driver: local
  grafana_data:
    driver: local
  seeder:
    driver: local

networks:
  front_net:
    driver: bridge
    name: devops-project-sk_front_net
  back_net:
    driver: bridge
    name: devops-project-sk_back_net
    internal: true
  back_bridge_net: # egress only
    driver: bridge
    name: devops-project-sk_bridge_net
    internal: false